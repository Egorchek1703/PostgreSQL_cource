***Буферный кеш и журнал***  
  
**==================> Устройство кеша в PostgreSQL <==================**  
  
**Кеш** - это выдленная область оперативной памяти под хранение часто используемых данных, например как в нашем случае - таблиц или их строк.  
Кеш эффективенее чем обычного хранения данных на диске, т.к. оперативная память работает намного быстрее чем диск.  
  
**Буфер** - это место под хранение данных (не заточенное под скорость доступа к ним). Грубо говоря буфер - это просто холодильник, а кеш - это записка на холодильнике позволяющая понять что где лежит для быстрого доступа внутри буфра (холодильника).  
  
Таким образом, **буферный кеш** - это холодильник и записка на нем одновременно.
  
В контексте PostgreSQL буфер - это место под хранение одной страницы размером 8 килобайт (+ в заголовке хранится информация из какого файла мы прочитали данную страницу). Данный параметр можно отконфигурировать под другое значение, но по умолчанию он равен 8 килобайтам.  
  
Соответственно, буферный кеш доступен всем обслуживающим клиентов процессам. Поэтому если один клиент выполнил определенный запрос и данные попали в кеш, то к этим данным смогут достучаться и другие клиенты, не выполняя запросы на диск.  
Ввиду того, что буфер является глобальным, логично, что он должен блокироваться при обращении к нему одним из обслуживающих процессов. Соответстственно, если мы поменяли какие-то данные, то пока мы их меняем, их не может менять другой процесс.  
  
*Размер кеша по умолчанию в PostgreSQL очень маленький - всего 128 килобайт.*  
  
Рано или поздно наступит момент, когда кеш заполнится, а нам нужно будет прочитать какую-то страницу, которой нет в нашем кеше. Значит нам необходимо выбрать какую-то страницу из кеша, вытеснить и на её место записать нужную нам страницу. В таких случаях начинает свою работу **алгоритм вытеснения**. Он убирает из кеша страницы, к которым запросы совершались меньше других, удаляет ее и на ее место записывает страницу которую клиент запрашивает сейчас.  
  
Также нужно понимать, что хеш не взаимодействует с диском постоянно, а делает это через определенные промежутки времени. Т.е. вполне возможна ситуация, когда данные изменены и изменения отражены в кеше, но на диск еще не записаны. Буфер, содержащий такие данные называется грязным. Поэтому когда алгоритм вытеснения собирается вытеснить грязный буфер, сперва его необходимо записать на диск.  
  
Размер кеша настраивается параметров который называется shared_buffers.  
Для наглядности работы с кешом, создадим тестовую таблицу и будем работать с ней в рамках текущего урока.  
```
    CREATE TABLE test_table (
        number integer
    )
```  
Также наполним таблицу данным и запустим очистку и сбор статистики для планировщика:
```
    INSERT INTO test_table SELECT * FROM generate_series(1, 100000);
    VACUUM ANALYZE test_table;
```  
Выведем размер буферного кеша у нашего экземпляра PostgreSQL с помощью :
```
    SHOW shared_buffers;
```    
  
При каждом перезапуске сервера PostgreSQL кеш очищается. Следовательно, чтобы посмотреть разницу в скорости запроса нам необходимо:  
1. перезапустить сервер  
2. выполнить запрос к нашей таблице test_table с помощью оператора EXPLAIN с флагом analyze (на данном этапе данные запишутся в кеш)  
3. повторно выполнить запрос, и сравнить скорость выполнения со скоростью из пункта 2  
  
```
    EXPLAIN(analyze, buffers, costs off, timing off)
    SELECT * FROM test_table;
```
В ответ получаем следующие строки:
  
    QUERY PLAN                      
\-----------------------------------------------------  
Seq Scan on test_table (actual rows=100000 loops=1)  
    Buffers: shared read=443  
Planning:  
    Buffers: shared hit=12 read=8  
Planning Time: 0.223 ms  
Execution Time: 7.325 ms  
(6 rows)  
\-----------------------------------------------------  
  
В данном ответе мы видим, что 443 страницы было записано в буффер "Buffers: shared hit=443"  
Также стоит обратить внимание, что запрос выполнялся **7.325 ms**  
Теперь повторим запрос и посмотрим сколько времени понадобится для чтения уже имеющихся в кеше данных  
```
    EXPLAIN(analyze, buffers, costs off, timing off)
    SELECT * FROM test_table;
```  
Результат:  
    QUERY PLAN                      
\-----------------------------------------------------  
Seq Scan on test_table (actual rows=100000 loops=1)  
    Buffers: shared read=443  
Planning:  
    Buffers: shared hit=12 read=8  
Planning Time: 0.031 ms  
Execution Time: 2.740 ms  
(6 rows)  
\-----------------------------------------------------  
  
Как видно из примера, запрос произошел практически в 4 раза быстрее.  
  
  
Если учесть, что может произойти какая-либо ошибка, вследствие которой упадет либо PostgreSQL, либо ОС, то логично заключить, что мы потеряем все данные из "грязных" буферов. Потерять данные мы не имеем права, поэтому существует журнал предзаписи WAL, содержащий в себе минимальные данные для того чтобы повторить операцию, которая была прервана. Важным условием тут является тот факт, что запись о попадании данных на диск должна быть записана раньше, чем сами данные попадут на диск (поэтому журнал и называется журналом **предзаписи**).  
  
Журнал предзаписи следует представлять как последовательный поток записей. Каждая запись имеет номер называемый LSN (Log Sequence Number - порядковый номер журнала). Чтобы вывести текущий LSN необходимо выполнить функцию pg_current_wal_lsn();  
```
    SELECT * FROM pg_current_wal_lsn();
```  
  
На наш запрос PostgreSQL-сервер вернул "0/4A52438". Фактически данные значение - это смещение в байтах относительно начала журнала (порядковый номер)  
  
Фактически журнал хранится на диске в отдельном каталоге **pg_wal**. Он порезан на сегменты, каждый по 16 МБ. Когда заканчивается один сегмент - начинается другой.  
Данный каталог можно посмотреть руками на хосте или можно выполнить функцию из терминального окна psql:
```
    SELECT pg_ls_waldir();
```  
  
Ввиду того, что мы не можем хранить бесконечное кол-во сегментов журнала WAL из-за соображений сохранения производительности сервера, следовательно, нам необходимо отправлять часть данных из кеша и удалять соответствующие сегменты из журнала.  
  
Для этого у нас существует процесс регистрирующий контрольные точки. Контрольная точка - это момент времени, когда необходимо отправить **все** данные из кеша (оперативной памяти) на диск, и как следствие - удалить все сегменты журнала WAL. При этом данные из кеша не вытесняются, а остаются, просто "грязные" страницы (буферы) записываются на диск. А сегменты журнала начинают писаться в пустом каталоге.  
  
По логике, в момент регистрации контрольной точки нам необходимо остановить сервер, произвести запись данных из оперативной памяти на диск (что может быть достаточно продолжительным процессом) и только после этого удалять сегменты журналов и запускать сервер. Очевидно, что такое поведение не приемлемо. Поэтому контрольная точка по сути своей является не столько точкой, сколько отрезком, конечная точка которого свидетельствует о возможности удалить определенные сегменты журнала WAL.  
  
В момент начала контрольной точки, мы запоминаем какие страницы у нас "грязные", а следовательно, запоминаем какие сегменты журналов мы должны будем удалить после успешного завершения контрольной точки.
  
Чтобы посмотреть как сервер восстанавливает данные, утраченные из оперативной памяти в реузльтате сбоя, опираясь на сегменты журнала текущей контрольной точки, необходимо убить процесс postmaster с помощью команды 
```
    kill -9 <pid> 
```  
  
После выполнения данной команды работа сервера будет прервана.  
```
    kill -9 3745 
```  
После чего нам необходимо запустить сервер:  
```
    pg_ctlcluster 16 main start
```  
Строчки которые появяться в log-файле:  
```
2025-01-07 04:53:27.691 MSK [4214] LOG:  starting PostgreSQL 16.6 (Ubuntu 16.6-0ubuntu0.24.04.1) on x86_64-pc-linux>
2025-01-07 04:53:27.691 MSK [4214] LOG:  listening on IPv4 address "127.0.0.1", port 5432
2025-01-07 04:53:27.694 MSK [4214] LOG:  listening on Unix socket "/var/run/postgresql/.s.PGSQL.5432"
2025-01-07 04:53:27.700 MSK [4217] LOG:  database system was interrupted; last known up at 2025-01-07 04:15:38 MSK
2025-01-07 04:53:27.994 MSK [4217] LOG:  database system was not properly shut down; automatic recovery in progress
2025-01-07 04:53:27.997 MSK [4217] LOG:  redo starts at 0/4A55488
2025-01-07 04:53:27.997 MSK [4217] LOG:  invalid record length at 0/4A55570: expected at least 24, got 0
2025-01-07 04:53:27.997 MSK [4217] LOG:  redo done at 0/4A55538 system usage: CPU: user: 0.00 s, system: 0.00 s, el>
2025-01-07 04:53:28.001 MSK [4215] LOG:  checkpoint starting: end-of-recovery immediate wait
2025-01-07 04:53:28.014 MSK [4215] LOG:  checkpoint complete: wrote 3 buffers (0.0%); 0 WAL file(s) added, 0 remove>
2025-01-07 04:53:28.019 MSK [4214] LOG:  database system is ready to accept connections
```  
Из log-файла видно, что данные в кеш восстанавливались на основе LSN = 0/4A55488.  
  
Порядок выполнения контрольных точек внутри журнала WAL:  
```
    LSN-1
    LSN-2
    LSN-3 <= Фиксируется начало контрольной точки (запоминается LSN и список "грязных" страниц до момента LSN-3)
    LSN-4 <= Данные продолжают записываться в WAL, в то время как "грязные" страницы (до LSN-3) отправляются на диск
    LSN-5 <= Все "грязные" страницы, которые были на момент LSN-3, успешно сброшены на диск
    LSN-6 <= Фиксируется завершение контрольной точки (Checkpoint Complete)
    LSN-7 <= Фиксируется начало новой контрольной точки от LSN-3 до LSN-7 и удаляются из журнала записи для восстановления от LSN-1 до LSN-3
```  
  
Нам как администратору PostgreSQL необходимо быть уверенным в том, что данные пишутся именно на диск и не используется никаких промежуточных кешей (например, кеш дискового массива). Или даже если используется, то мы должны быть уверены, что данное устройство отвечающее за запись данных на диск подпитано вспомогательным аккумулятором, например, на случай полного отключения электричества, а следовательно, способно успеть перенести данные на сам диск. Если мы не уверены в этом, значит мы не можем говорить о гарантиях сохранности данных, а это является одной из важнейших задач администратора СУБД.  
  
Важно понимать, что исходя из вышеописанной логики, когда мы выполняем COMMIT, PostgreSQL должен синхронизировать данные на диске и убедиться, что они корректно записаны.  
  
Процессы выполняющие взаимодействие вышеописанным способом:
1. walwriter - записывает журнал предзаписи в фоновом режиме
2. checkpointer - процесс выполняющий контрольные точки и сбрасывающий все грязные буферы на диск
3. bgwriter - процесс который также как и checkpointer записывает грязные буферы на диск, но делает это лишь с теми страницами, которые будут скоро вытеснены из буферного кеша алгоритмом вытеснения. Это сделано для того чтобы когда нам понадобится свежая страничка не из кеша, и мы начнем помещать ее в кеш, а следовательно, вытеснять старую страницу, которую редко использовали, то нам не придется переносить грязную старую страницу из кеша на диск тем же процессом, который выполняет запрос свежей страницы не из кеша, а следовательно это ударит по производительности самого запроса. Грубо говоря bgwriter бежут немного впереди алгоритма вытеснения и записывает данные редко используемых страниц из кеша на диск, чтобы когда поридет момент вытеснения данной страницы, ее можно было бы просто удалить из кеша, а не переносить на диск в рамках процесса, который выполняет запрос за свежей страницей данных.  
  
Т.к. журна используется не только для восстановления данных, но и для других целей (например, для репликации сервера), у него есть несколько уровней. Уровни журнала:  
1. Minimal - гарантирует только лишь восстановление после сбоя  
2. Replica (по умолчанию) - выполняет резервное копирование и репликацию, помимо гарантии восстановления. Это позволяет отправлять данные на другой сервер и в случае падения работающего быстро переключиться на запасную ноду.  
3. Logical - логическая репликация. Грубо говоря, на данном уровне журнала мы можем декодировать изменные данные и подробно увидеть, что было изменено.   